<!DOCTYPE html><html lang="en"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=5"><title>Zheng Zhang</title><meta name="author" content="Zheng Zhang"><link rel="shortcut icon" href="/img/favicon.png"><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.13.0/css/all.min.css"><meta name="generator" content="Hexo 4.2.1"></head><body><header id="page_header"><div class="header_wrap"><div id="blog_name"><a class="blog_title" id="site-name" href="/"></a></div><button class="menus_icon"><div class="navicon"></div></button><ul class="menus_items"><li class="menus_item"><a class="site-page" href="/"> </a></li></ul></div></header><main id="page_main"><div class="side-card sticky"><div class="card-wrap" itemscope itemtype="http://schema.org/Person"><div class="author-avatar"><img class="avatar-img" src="/img/avatar.jpg" onerror="this.onerror=null;this.src='/img/profile.png'" alt="avatar"></div><div class="author-discrip"><h3>Zheng Zhang</h3><p class="author-bio">Researcher&amp;Coder</p></div><div class="author-links"><button class="btn m-social-links">Links</button><ul class="social-icons"><li><a class="social-icon" href target="_blank"><i class="enable" aria-hidden="true"></i></a></li><li><a class="social-icon" href="https://github.com/stupidZZ/" target="_blank"><i class="fab fa-github" aria-hidden="true"></i></a></li><li><a class="social-icon" href="https://www.linkedin.com/in/zheng-zhang-07936152/" target="_blank"><i class="fab fa-linkedin" aria-hidden="true"></i></a></li><li><a class="social-icon" href="https://scholar.google.com/citations?user=nZ_PVbsAAAAJ&amp;hl=en /" target="_blank"><i class="fas fa-graduation-cap" aria-hidden="true"></i></a></li></ul></div></div><div class="card-content"><a href="https://clustrmaps.com/site/1bndc" target="_blank" rel="noopener"><img src="//clustrmaps.com/map_v2.png?cl=6dbee2&amp;w=300&amp;t=n&amp;d=mSqNmjeXj0eTNzbmfm_zdKnVPjZIeAhw1mjIHj7GJks&amp;co=ffffff&amp;ct=7a7a7a"></a></div></div><div class="page" itemscope itemtype="http://schema.org/CreativeWork"><h2 class="page-title">homepage</h2><article><h2 id="Research"><a href="#Research" class="headerlink" title="Research"></a>Research</h2><p>My long-term research interest is to find a path to build a <strong>universal learning system</strong>, and my short-term research interest is to explore a better path to build <strong>universal visual perception system</strong>. Now, I am closely collaborating with <a href="https://ancientmooner.github.io/" target="_blank" rel="noopener">Han Hu</a>, [Houwen Peng] (<a href="https://houwenpeng.com" target="_blank" rel="noopener">https://houwenpeng.com</a>) and <a href="https://www.microsoft.com/en-us/research/people/stevelin/" target="_blank" rel="noopener">Steve Lin</a> at Microsoft Research Asia. Previously, I closely collaborated with <a href="http://yue-cao.me/" target="_blank" rel="noopener">Yue Cao</a> and <a href="https://scholar.google.com/citations?user=02RXI00AAAAJ&hl=en" target="_blank" rel="noopener">Xizhou Zhu</a>. Meanwhile, I was mentored by <a href="https://scholar.google.com/citations?user=UeltiQ4AAAAJ&hl=zh-CN" target="_blank" rel="noopener">Prof. Xiang Bai</a> as a student at Huazhong University of Science and Technology, and by <a href="https://jifengdai.org/" target="_blank" rel="noopener">Jifeng Dai</a> as a young researcher at Microsoft Research Asia. </p>
<p><strong>Please drop me an email if you are interested in doing research with me.</strong></p>
<p><strong>E-mail</strong>: macaroniz1990 [at] outlook [dot] com, zhez [at] microsoft [dot] com</p>
<h2 id="Professional-Services"><a href="#Professional-Services" class="headerlink" title="Professional Services"></a>Professional Services</h2><p><small> Senior Program Committee member: AAAI2022 </small><br><small> Conference reviewer: CVPR, ICCV, ECCV, NeurIPS, ICML, AAAI, WACV, ACCV, IJCAI </small><br><small> Journal reviewer: TPAMI, IJCV, CVIU </small></p>
<h2 id="Publications"><a href="#Publications" class="headerlink" title="Publications"></a>Publications</h2><p><small>(†Interns or Students, *Equal Contribution)</small></p>
<p><strong>Side Adapter Network for Open-Vocabulary Semantic Segmentation</strong><br><small>Mengde Xu*†, <strong>Zheng Zhang*</strong>, Fangyun Wei, Han Hu, Xiang Bai, <em>IEEE Conference on Computer Vision and Pattern Recognition</em>(<strong>CVPR</strong>), 2023, <font color=Tomato><strong>Hightlight</strong></font>, <strong><a href="https://arxiv.org/abs/2302.12242" target="_blank" rel="noopener">[PDF]</a><a href="https://mendelxu.github.io/SAN/" target="_blank" rel="noopener">[Project]</a><a href="https://github.com/MendelXu/SAN" target="_blank" rel="noopener">[Code]</a></strong></small></p>
<p><strong>All in Tokens: Unifying Output Space of Visual Tasks via Soft Token</strong><br><small>Jia Ning*†, Chen Li*†, <strong>Zheng Zhang*</strong>, Chunyu Wang, Zigang Geng, Qi Dai, Kun He, Han Hu, <em>International Conference on Computer Vision</em>(<strong>ICCV</strong>), 2023, <font color=Tomato><strong>Oral</strong></font>, <strong><a href="https://arxiv.org/abs/2301.02229" target="_blank" rel="noopener">[PDF]</a><a href="https://github.com/SwinTransformer/AiT" target="_blank" rel="noopener">[Code]</a></strong></small></p>
<p><strong>Exploring Discrete Diffusion Models for Image Captioning</strong><br><small>Zixin Zhu*†, Yixuan Wei*†, Jianfeng Wang, Zhe Gan, <strong>Zheng Zhang</strong>, Le Wang, Gang Hua, Lijuan Wang, Zicheng Liu, Han Hu, <em>Arxiv</em>, 2023, <strong><a href="https://arxiv.org/pdf/2211.11694.pdf" target="_blank" rel="noopener">[PDF]</a><a href="https://github.com/buxiangzhiren/DDCap" target="_blank" rel="noopener">[Code]</a></strong></small></p>
<p><strong>On data scaling in masked image modeling</strong><br><small>Zhenda Xie*†, <strong>Zheng Zhang*</strong>, Yue Cao*, Yutong Lin, Yixuan Wei, Qi Dai, Han Hu, <em>IEEE Conference on Computer Vision and Pattern Recognition</em>(<strong>CVPR</strong>), 2023, <strong><a href="https://arxiv.org/abs/2206.04664" target="_blank" rel="noopener">[PDF]</a></strong></small></p>
<p><strong>Revealing the dark secrets of masked image modeling</strong><br><small>Zhenda Xie*†, Zigang Geng*†, Jingcheng Hu, <strong>Zheng Zhang</strong>, Han Hu, Yue Cao, <em>IEEE Conference on Computer Vision and Pattern Recognition</em>(<strong>CVPR</strong>), 2023, <strong><a href="https://arxiv.org/abs/2205.13543" target="_blank" rel="noopener">[PDF]</a></strong></small></p>
<p><strong>Contrastive learning rivals masked image modeling in fine-tuning via feature distillation</strong><br><small>Yixuan Wei*†, Han Hu*, Zhenda Xie, <strong>Zheng Zhang</strong>, Yue Cao, Jianmin Bao, Dong Chen, Baining Guo, <em>International Conference on Computer Vision</em>(<strong>ICCV</strong>), 2023, <strong><a href="https://arxiv.org/abs/2205.14141" target="_blank" rel="noopener">[PDF]</a><a href="https://github.com/SwinTransformer/Feature-Distillation" target="_blank" rel="noopener">[Code]</a></strong></small></p>
<p><strong>SimMIM: A simple framework for masked image modeling</strong><br><small>Zhenda Xie*†, <strong>Zheng Zhang*</strong>, Yue Cao*, Yutong Lin, Jianmin Bao, Zhuliang Yao, Qi Dai, Han Hu*, <em>IEEE Conference on Computer Vision and Pattern Recognition</em>(<strong>CVPR</strong>), 2022, <strong><a href="https://arxiv.org/pdf/2111.09886.pdf" target="_blank" rel="noopener">[PDF]</a><a href="https://github.com/microsoft/SimMIM" target="_blank" rel="noopener">[Code]</a></strong></small></p>
<p><strong>Swin Transformer V2: Scaling Up Capacity and Resolution</strong><br><small>Ze Liu*†, Han Hu*, Yutong Lin, Zhuliang Yao, Zhenda Xie, Yixuan Wei, Jia Ning, Yue Cao, <strong>Zheng Zhang</strong>, Li Dong, Furu Wei, Baining Guo, <em>IEEE Conference on Computer Vision and Pattern Recognition</em>(<strong>CVPR</strong>), 2022, <strong><a href="https://arxiv.org/pdf/2111.09883.pdf" target="_blank" rel="noopener">[PDF]</a><a href="https://github.com/microsoft/Swin-Transformer" target="_blank" rel="noopener">[Code]</a></strong></small></p>
<p><strong>Video Swin Transformer</strong><br><small>Ze Liu*†, Jia Ning*†, Yue Cao, Yixuan Wei†, <strong>Zheng Zhang</strong>, Steve Lin, Han Hu, <em>IEEE Conference on Computer Vision and Pattern Recognition</em>(<strong>CVPR</strong>), 2022, <strong><a href="https://arxiv.org/abs/2106.13230" target="_blank" rel="noopener">[PDF]</a><a href="https://github.com/SwinTransformer/Video-Swin-Transformer" target="_blank" rel="noopener">[Code]</a></strong></small></p>
<p><strong>A Simple Baseline for Zero-shot Semantic Segmentation with Pre-trained Vision-language Model</strong><br><small>Mengde Xu*†, <strong>Zheng Zhang*</strong>, Fangyun Wei*, Yutong Lin, Yue Cao, Han Hu, Xiang Bai, <em>Europe Conference on Computer Vision(<strong>ECCV</strong>)</em>, 2022, <strong><a href="https://arxiv.org/pdf/2112.14757.pdf" target="_blank" rel="noopener">[PDF]</a><a href="https://github.com/MendelXu/zsseg.baseline" target="_blank" rel="noopener">[Code]</a></strong></small></p>
<p><strong>Bootstrap Your Object Detector via Mixed Training</strong><br><small>Mengde Xu*, <strong>Zheng Zhang*</strong>, Fangyun Wei*, Yutong Lin*, Yue Cao, Stephen Lin, Han Hu, Xiang Bai, <em>Neural Information Processing Systems</em>(<strong>NeurIPS</strong>), 2021, <font color=Tomato><strong>Spotlight</strong></font>, <strong><a href="https://arxiv.org/abs/2111.03056" target="_blank" rel="noopener">[PDF]</a><a href="https://github.com/MendelXu/MixTraining" target="_blank" rel="noopener">[Code]</a></strong></small></p>
<p><strong>Breaking Shortcut: Exploring Fully Convolutional Cycle-Consistency for Video Correspondence Learning</strong><br><small>Yansong Tang*†, Zhenyu Jiang*†, Zhenda Xie*†, Yue Cao, <strong>Zheng Zhang</strong>, Philip HS Torr, Han Hu, <em>International Conference on Computer Vision（<strong>ICCV</strong>) Workshop</em>, 2021, <strong><a href="https://arxiv.org/pdf/2105.05838.pdf" target="_blank" rel="noopener">[PDF]</a><a href="https://github.com/Steve-Tod/STFC3" target="_blank" rel="noopener">[Code]</a></strong></small></p>
<p><strong>Self-supervised Learning with Swin Transformers</strong><br><small>Zhenda Xie*†, Yutong Lin*†, Zhuliang Yao†, <strong>Zheng Zhang</strong>, Qi Dai, Yue Cao, Han Hu, <em>Arxiv</em>, 2021, <strong><a href="https://arxiv.org/abs/2105.04553" target="_blank" rel="noopener">[PDF]</a><a href="https://github.com/SwinTransformer/Transformer-SSL" target="_blank" rel="noopener">[Code]</a></strong></small></p>
<p><strong>End-to-End Semi-Supervised Object Detection with Soft Teacher</strong><br><small>Mengde Xu*†, <strong>Zheng Zhang*†</strong>, Han Hu*, Jianfeng Wang, Lijuan Wang, Fangyun Wei, Xiang Bai, Zicheng Liu, <em>International Conference on Computer Vision</em>(<strong>ICCV</strong>), 2021, <strong><a href="https://arxiv.org/pdf/2106.09018.pdf" target="_blank" rel="noopener">[PDF]</a><a href="https://github.com/microsoft/SoftTeacher" target="_blank" rel="noopener">[Code]</a></strong></small></p>
<p><strong>Swin Transformer: Hierarchical Vision Transformer using Shifted Windows</strong><br><small>Ze Liu*†, Yutong Lin*†, Yue Cao*, Han Hu*, Yixuan Wei†, <strong>Zheng Zhang</strong>, Steve Lin, Baining Guo, <em>International Conference on Computer Vision</em>(<strong>ICCV</strong>), 2021, <font color=#FDD017><strong>Best Paper, Marr Prize</strong></font>, <strong><a href="https://arxiv.org/abs/2103.14030" target="_blank" rel="noopener">[PDF]</a><a href="https://github.com/microsoft/Swin-Transformer" target="_blank" rel="noopener">[Code]</a></strong></small></p>
<p><strong>Group-Free 3D Object Detection via Transformers</strong><br><small>Ze Liu†, <strong>Zheng Zhang</strong>, Yue Cao, Han Hu, Xin Tong, <em>International Conference on Computer Vision</em>(<strong>ICCV</strong>), 2021, <strong><a href="https://arxiv.org/abs/2104.00678" target="_blank" rel="noopener">[PDF]</a><a href="https://github.com/zeliu98/Group-Free-3D" target="_blank" rel="noopener">[Code@Official]</a><a href="https://github.com/open-mmlab/mmdetection3d/blob/master/configs/groupfree3d/README.md" target="_blank" rel="noopener">[Code@MMDetection3D]</a></strong></small></p>
<p><strong>Propagate Yourself: Exploring Pixel-Level Consistency for Unsupervised Visual Representation Learning</strong><br><small>Zhenda Xie*†, Yutong Lin*†, <strong>Zheng Zhang</strong>, Yue Cao, Stephen Lin, Han Hu, <em>IEEE Conference on Computer Vision and Pattern Recognition</em>(<strong>CVPR</strong>), 2020, <strong><a href="https://arxiv.org/abs/2011.10043" target="_blank" rel="noopener">[PDF]</a><a href="https://github.com/zdaxie/PixPro" target="_blank" rel="noopener">[Code]</a></strong></small></p>
<p><strong>RepPoints V2: Verification Meets Regression for Object Detection</strong><br><small>Yihong Chen†, <strong>Zheng Zhang</strong>, Yue Cao, Liwei Wang, Steve Lin, Han Hu, <em>Neural Information Processing Systems</em>(<strong>NeurIPS</strong>), 2020, <strong><a href="https://arxiv.org/abs/2007.08508" target="_blank" rel="noopener">[PDF]</a><a href="https://github.com/Scalsol/RepPointsV2" target="_blank" rel="noopener">[Code]</a></strong></small></p>
<p><strong>Parametric Instance Classification for Unsupervised Visual Feature Learning</strong><br><small>Yue Cao*, Zhenda Xie*†, Bin Liu*†, Yutong Lin†, <strong>Zheng Zhang</strong>, Han Hu, <em>Neural Information Processing Systems</em>(<strong>NeurIPS</strong>), 2020, <strong><a href="https://arxiv.org/abs/2006.14618" target="_blank" rel="noopener">[PDF]</a><a href="https://github.com/bl0/PIC" target="_blank" rel="noopener">[Code]</a></strong></small></p>
<p><strong>Spatially Adaptive Inference with Stochastic Feature Sampling and Interpolation</strong><br><small>Zhenda Xie*†, <strong>Zheng Zhang*</strong>, Xizhou Zhu*†, Gao Huang, Stephen Lin, <em>Europe Conference on Computer Vision</em>(<strong>ECCV</strong>), 2020, <font color=Tomato><strong>Oral</strong></font>, <strong><a href="https://arxiv.org/abs/2003.08866" target="_blank" rel="noopener">[PDF]</a><a href="https://github.com/zdaxie/SpatiallyAdaptiveInference-Detection" target="_blank" rel="noopener">[Code]</a></strong></small></p>
<p><strong>A Closer Look at Local Aggregation Operators in Point Cloud Analysis</strong><br><small>Ze Liu*†, Han Hu*, Yue Cao, <strong>Zheng Zhang</strong>, Xin Tong, <em>Europe Conference on Computer Vision</em>(<strong>ECCV</strong>), 2020, <strong><a href="https://arxiv.org/abs/2007.01294" target="_blank" rel="noopener">[PDF]</a><a href="https://github.com/zeliu98/CloserLook3D" target="_blank" rel="noopener">[Code]</a></strong></small></p>
<p><strong>Disentangled Non-Local Neural Networks</strong><br><small>Minghao Yin*†, Zhuliang Yao*†, Yue Cao, Xiu Li, <strong>Zheng Zhang</strong>, Steve Lin, Han Hu, <em>Europe Conference on Computer Vision</em>(<strong>ECCV</strong>), 2020, <strong><a href="https://arxiv.org/abs/2006.06668" target="_blank" rel="noopener">[PDF]</a><a href="https://github.com/Howal/DNL-Object-Detection" target="_blank" rel="noopener">[Code@Det]</a><a href="https://github.com/yinmh17/DNL-Semantic-Segmentation" target="_blank" rel="noopener">[Code@Seg]</a></strong></small></p>
<p><strong>Dense RepPoints: Representing Visual Objects With Dense Point Sets</strong><br><small>Ze Yang*†, Yinghao Xu*†, Han Xue*†, <strong>Zheng Zhang</strong>, Raquel Urtasun, Liwei Wang, Stephen Lin, Han Hu, <em>Europe Conference on Computer Vision</em>(<strong>ECCV</strong>), 2020, <strong><a href="https://arxiv.org/abs/1912.11473" target="_blank" rel="noopener">[PDF]</a><a href="https://github.com/justimyhxu/Dense-RepPoints" target="_blank" rel="noopener">[Code]</a></strong></small></p>
<p><strong>Negative Margin Matters: Understanding Margin in Few-shot Classification</strong><br><small>Bin Liu†, Yue Cao, Yutong Lin†, Qi Li†, <strong>Zheng Zhang</strong>, Mingsheng Long, Han Hu, <em>Europe Conference on Computer Vision</em>(<strong>ECCV</strong>), 2020, <font color=Tomato><strong>Spotlight</strong></font>, <strong><a href="https://arxiv.org/abs/2003.12060" target="_blank" rel="noopener">[PDF]</a><a href="https://github.com/bl0/negative-margin.few-shot" target="_blank" rel="noopener">[Code]</a></strong></small></p>
<p><strong>Local Relation Networks For Image Recognition</strong><br><small>Han Hu, <strong>Zheng Zhang</strong>, Zhenda Xie, Stephen Lin, <em>IEEE International Conference on Computer Vision</em>(<strong>ICCV</strong>), 2019, <strong><a href="https://arxiv.org/abs/1904.11491" target="_blank" rel="noopener">[PDF]</a></strong></small></p>
<p><strong>Spatial-Temporal Relation Networks For Multi-Object Tracking</strong><br><small>Jiarui Xu†, Yue Cao†, <strong>Zheng Zhang</strong>, Han Hu, <em>IEEE International Conference on Computer Vision</em>(<strong>ICCV</strong>), 2019, <strong><a href="https://arxiv.org/abs/1904.11489" target="_blank" rel="noopener">[PDF]</a></strong></small></p>
<p><strong>An Empirical Study Of Spatial Attention Mechanisms In Deep Networks</strong><br><small>Xizhou Zhu*†, Dazhi Cheng*†, <strong>Zheng Zhang*</strong>, Stephen Lin, Jifeng Dai, <em>IEEE International Conference on Computer Vision</em>(<strong>ICCV</strong>), 2019, <strong><a href="https://arxiv.org/abs/1904.05873" target="_blank" rel="noopener">[PDF]</a><a href="https://github.com/open-mmlab/mmdetection/tree/master/configs/empirical_attention" target="_blank" rel="noopener">[Code]</a></strong></small></p>
<p><strong>Integrated Object Detection And Tracking With Tracklet-Conditioned Detection</strong><br><small><strong>Zheng Zhang*</strong>, Dazhi Cheng*†, Xizhou Zhu*†, Stephen Lin, Jifeng Dai, <em>Arxiv</em>, 2018, <strong><a href="https://arxiv.org/abs/1811.11167" target="_blank" rel="noopener">[PDF]</a></strong></small></p>
<p><strong>Relation networks for object detection</strong><br><small>Han Hu*, Jiayuan Gu*†, <strong>Zheng Zhang*</strong>, Jifeng Dai, Yichen Wei, <em>IEEE Conference on Computer Vision and Pattern Recognition</em>(<strong>CVPR</strong>), 2018, <font color=Tomato><strong>Oral</strong></font>, <strong><a href="https://arxiv.org/abs/1711.11575" target="_blank" rel="noopener">[PDF]</a><a href="https://github.com/msracver/Relation-Networks-for-Object-Detection" target="_blank" rel="noopener">[Code]</a></strong></small></p>
<p><strong>Deformable Convolutional Networks–COCO Detection And Segmentation Challenge 2017 Entry</strong><br><small>Haozhi Qi†, <strong>Zheng Zhang</strong>, Bin Xiao, Han Hu, Bowen Cheng, Yichen Wei, Jifeng Dai, <em>ICCV COCO Challenge Workshop</em>(<strong>ICCV Workshop</strong>), 2017</small></p>
<p><strong>Symmetry-Based Object Proposal For Text Detection</strong><br><small>Xuelei Zhang, <strong>Zheng Zhang</strong>, Chengquan Zhang, Xiang Bai, <em>International Conference on Pattern Recognition</em>(<strong>ICPR</strong>), 2016</small></p>
<p><strong>Multi-Oriented Text Detection With Fully Convolutional Networks</strong><br><small><strong>Zheng Zhang*</strong>, Chengquan Zhang*, Wei Shen, Cong Yao, Wenyu Liu, Xiang Bai, <em>IEEE Conference on Computer Vision and Pattern Recognition</em>(<strong>CVPR</strong>), 2016, <strong><a href="https://openaccess.thecvf.com/content_cvpr_2016/papers/Zhang_Multi-Oriented_Text_Detection_CVPR_2016_paper.pdf" target="_blank" rel="noopener">[PDF]</a><a href="https://github.com/stupidZZ/FCN_Text" target="_blank" rel="noopener">[Code]</a></strong></small></p>
<p><strong>Symmetry-Based Text Line Detection In Natural Scenes</strong><br><small><strong>Zheng Zhang</strong>, Wei Shen, Cong Yao, Xiang Bai, <em>IEEE Conference on Computer Vision and Pattern Recognition</em>(<strong>CVPR</strong>), 2015, <strong><a href="https://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Zhang_Symmetry-Based_Text_Line_2015_CVPR_paper.pdf" target="_blank" rel="noopener">[PDF]</a><a href="https://github.com/stupidZZ/Symmetry_Text_Line_Detection" target="_blank" rel="noopener">[Code]</a></strong></small></p>
<h2 id="Awards"><a href="#Awards" class="headerlink" title="Awards"></a>Awards</h2><p><strong>3rd in COCO Object Detection Competition and 4th in COCO Instance Segmentation Competition</strong>, 2017<br><strong>National Scholarship, Huazhong University of Science and Technology</strong>, 2015<br><strong>ACM ICPC Regional <font color=#FDD017>Gold Medal</font></strong>, Changsha, 2013<br><strong>Excellent Internship Award</strong>, Microsoft Research Asia, 2013<br><strong>Imagine Cup(China) Second Price</strong>, 2012</p>
</article></div></main><div class="nav-wrap"><div class="nav"><button class="site-nav"><div class="navicon"></div></button><ul class="nav_items"><li class="nav_item"><a class="nav-page" href="/"> </a></li></ul></div><div class="cd-top"><i class="fa fa-arrow-up" aria-hidden="true"></i></div></div><footer id="page_footer"><div class="footer_wrap"><div class="copyright">&copy;2020 - 2023 by Zheng Zhang</div><div class="theme-info">Powered by <a href="https://hexo.io" target="_blank" rel="nofollow noopener">Hexo</a> & <a href="https://github.com/PhosphorW/hexo-theme-academia" target="_blank" rel="nofollow noopener">Academia Theme</a></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/jquery-pjax@latest/jquery.pjax.min.js"></script><script src="/js/main.js"></script></body></html>